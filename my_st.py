import streamlit as st
import cv2
import mediapipe as mp
import time
import numpy as np
import av
from streamlit_webrtc import webrtc_streamer, VideoProcessorBase, RTCConfiguration

# ---------------- Mediapipe ì´ˆê¸°í™” ----------------
mp_face = mp.solutions.face_detection
mp_hands = mp.solutions.hands
mp_draw = mp.solutions.drawing_utils

FACE_DETECTOR = mp_face.FaceDetection(model_selection=0, min_detection_confidence=0.4)
HAND_DETECTOR = mp_hands.Hands(max_num_hands=2, min_detection_confidence=0.5)

# ---------------- ì›¹ ì•± ì „ì—­ ë³€ìˆ˜ ì„¤ì • ----------------
TARGET_A_MIN, TARGET_A_MAX = 43, 47
TARGET_B_MIN, TARGET_B_MAX = 12, 15
COUNTDOWN_TIME = 3.0  # ì¹´ìš´íŠ¸ë‹¤ìš´ ì‹œê°„ ì„¤ì •


# ---------------- Victory ì œìŠ¤ì²˜ íŒë‹¨ ----------------
def is_victory(lms, w, h):
    """ê²€ì§€+ì¤‘ì§€ í´ì§, ì•½ì§€+ìƒˆë¼ ì ‘í˜ì´ë©´ V ì‚¬ì¸ True"""

    def c(i):
        lm = lms.landmark[i]
        return int(lm.x * w), int(lm.y * h)

    i_tip = c(8)
    m_tip = c(12)
    r_tip = c(16)
    p_tip = c(20)

    i_kn = c(5)
    m_kn = c(9)
    r_kn = c(13)
    p_kn = c(17)

    return i_tip[1] < i_kn[1] and m_tip[1] < m_kn[1] and r_tip[1] > r_kn[1] and p_tip[1] > p_kn[1]


# ---------------- ë¹„ìœ¨ ê³„ì‚° í•¨ìˆ˜ ----------------
def get_face_distances(detection):
    keypoints = detection.location_data.relative_keypoints
    bbox_h = detection.location_data.relative_bounding_box.height

    if bbox_h == 0:
        return {'eye_mouth_ratio': 0.0, 'nose_mouth_ratio': 0.0}

    y_eye_r = keypoints[1].y
    y_eye_l = keypoints[0].y
    y_eye_center = (y_eye_r + y_eye_l) / 2
    y_mouth = keypoints[3].y
    y_nose = keypoints[2].y

    distance_eye_mouth_norm = abs(y_mouth - y_eye_center)
    eye_mouth_ratio = distance_eye_mouth_norm / bbox_h

    distance_nose_mouth_norm = abs(y_mouth - y_nose)
    nose_mouth_ratio = distance_nose_mouth_norm / bbox_h

    return {
        'eye_mouth_ratio': eye_mouth_ratio,
        'nose_mouth_ratio': nose_mouth_ratio
    }


# ---------------- ê²Œì´ì§€ ê·¸ë¦¬ê¸° í•¨ìˆ˜ ----------------
def draw_gauge(img, ratio_percent, x_offset, target_min, target_max, label):
    """í™”ë©´ ì™¼ìª½ì— ìˆ˜ì§ ê²Œì´ì§€ë¥¼ ê·¸ë¦½ë‹ˆë‹¤."""
    gauge_x, gauge_y = 50 + x_offset, 80
    gauge_w, gauge_h = 20, 200

    ratio_percent_clamped = max(0, min(100, ratio_percent))

    is_target = target_min <= ratio_percent_clamped <= target_max

    target_color = (0, 255, 0)
    base_color = (255, 255, 255)
    fill_color = target_color if is_target else (0, 0, 255)

    # ê²Œì´ì§€ ë°°ê²½ (í…Œë‘ë¦¬)
    cv2.rectangle(img, (gauge_x, gauge_y), (gauge_x + gauge_w, gauge_y + gauge_h), base_color, 2)

    # ê²Œì´ì§€ ì±„ìš°ê¸°
    fill_height = int(gauge_h * (ratio_percent_clamped / 100))
    fill_y_start = gauge_y + gauge_h - fill_height
    cv2.rectangle(img, (gauge_x, fill_y_start), (gauge_x + gauge_w, gauge_y + gauge_h), fill_color, cv2.FILLED)

    # íƒ€ê²Ÿ ì˜ì—­ í‘œì‹œ
    y_min = gauge_y + gauge_h - int(gauge_h * (target_min / 100))
    y_max = gauge_y + gauge_h - int(gauge_h * (target_max / 100))

    cv2.line(img, (gauge_x - 5, y_min), (gauge_x + gauge_w + 5, y_min), (0, 255, 255), 1)
    cv2.line(img, (gauge_x - 5, y_max), (gauge_x + gauge_w + 5, y_max), (0, 255, 255), 1)

    cv2.putText(img, label, (gauge_x - 10, gauge_y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, base_color, 1)
    cv2.putText(img, f"{ratio_percent_clamped}%", (gauge_x - 10, gauge_y + gauge_h + 30),
                cv2.FONT_HERSHEY_SIMPLEX, 0.6, base_color, 2)

    return is_target, ratio_percent_clamped


# ---------------- VideoProcessor í´ë˜ìŠ¤ (í•µì‹¬) ----------------
class VideoProcessor(VideoProcessorBase):

    def __init__(self):
        # ìº¡ì²˜ ìƒíƒœ
        self.captured = False
        self.last_capture_time = 0

        # ì¹´ìš´íŠ¸ë‹¤ìš´ ìƒíƒœ
        self.countdown_active = False
        self.countdown_start_time = 0

    def recv(self, frame: av.VideoFrame) -> av.VideoFrame:
        img = frame.to_ndarray(format="bgr24")
        img_h, img_w, _ = img.shape
        rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

        # ---------------- 1. ì–¼êµ´ ì¸ì‹ ë° ë¹„ìœ¨ í™•ì¸ ----------------
        face_res = FACE_DETECTOR.process(rgb)
        face_detected = False
        ratio_ok_A, ratio_ok_B = False, False
        ratio_A_percent, ratio_B_percent = 0, 0

        if face_res.detections:
            face_detected = True
            d = face_res.detections[0]

            current_ratios = get_face_distances(d)

            ratio_A_percent = int(current_ratios['eye_mouth_ratio'] * 100)
            ratio_B_percent = int(current_ratios['nose_mouth_ratio'] * 100)

            ratio_ok_A = TARGET_A_MIN <= ratio_A_percent <= TARGET_A_MAX
            ratio_ok_B = TARGET_B_MIN <= ratio_B_percent <= TARGET_B_MAX

        # ---------------- 2. ì† ì¸ì‹ ë° V ì‚¬ì¸ í™•ì¸ ----------------
        hand_res = HAND_DETECTOR.process(rgb)
        victory_detected = False

        if hand_res.multi_hand_landmarks:
            for handLms in hand_res.multi_hand_landmarks:
                if is_victory(handLms, img_w, img_h):
                    victory_detected = True
                    cv2.putText(img, "VICTORY!", (50, 300),
                                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 3)
                    break

        # ---------------- 3. ê²Œì´ì§€ í‘œì‹œ ----------------
        draw_gauge(img, ratio_A_percent, 0, TARGET_A_MIN, TARGET_A_MAX, "E-M Ratio")
        draw_gauge(img, ratio_B_percent, 70, TARGET_B_MIN, TARGET_B_MAX, "N-M Ratio")

        total_ratio_ok = ratio_ok_A and ratio_ok_B

        all_conditions_met = face_detected and victory_detected and total_ratio_ok

        # ---------------- 4. ì¹´ìš´íŠ¸ë‹¤ìš´ ë° ìº¡ì²˜ ë¡œì§ (ì„¸ì…˜ ìƒíƒœ ë³µì›) ----------------
        if all_conditions_met:
            # A. ëª¨ë“  ì¡°ê±´ ì¶©ì¡± & ìº¡ì²˜ ëŒ€ê¸° ìƒíƒœ -> ì¹´ìš´íŠ¸ë‹¤ìš´ ì‹œì‘
            if not self.captured and not self.countdown_active:
                self.countdown_active = True
                self.countdown_start_time = time.time()
                st.session_state.capture_message = f"ì¹´ìš´íŠ¸ë‹¤ìš´ ì‹œì‘! {COUNTDOWN_TIME}ì´ˆ ìœ ì§€í•˜ì„¸ìš”."

            # B. ì¹´ìš´íŠ¸ë‹¤ìš´ ì§„í–‰ ì¤‘
            if self.countdown_active:
                elapsed = time.time() - self.countdown_start_time
                countdown_value = COUNTDOWN_TIME - elapsed

                # ì¹´ìš´íŠ¸ë‹¤ìš´ í…ìŠ¤íŠ¸ í‘œì‹œ
                countdown_display = max(0, int(countdown_value) + 1)

                cv2.putText(img, f"Capturing in: {countdown_display}", (img_w // 2 - 150, img_h // 2),
                            cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 255), 4)

                # C. ì¹´ìš´íŠ¸ë‹¤ìš´ ì¢…ë£Œ -> ìº¡ì²˜ ì‹¤í–‰
                if countdown_value <= 0:
                    self.countdown_active = False
                    self.captured = True
                    self.last_capture_time = time.time()

                    # â­â­ í•µì‹¬: set_result ëŒ€ì‹  st.session_stateì— ì§ì ‘ ì €ì¥í•˜ê³  rerun í˜¸ì¶œ ë³µì› â­â­
                    # (Legacy API í™˜ê²½ì—ì„œ ìº¡ì²˜ UI ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•œ ìœ ì¼í•œ ë°©ë²•ì¼ ìˆ˜ ìˆìŒ)
                    st.session_state.captured_image_bytes = cv2.imencode('.png', img)[1].tobytes()
                    st.session_state.capture_ready = True
                    st.session_state.capture_message = "âœ… ì´¬ì˜ ì„±ê³µ! ì•„ë˜ì—ì„œ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”."
                    st.rerun()  # UI ì—…ë°ì´íŠ¸ ê°•ì œ ìš”ì²­

        else:
            # ì¡°ê±´ ë¶ˆì¶©ì¡± ì‹œ ì¹´ìš´íŠ¸ë‹¤ìš´ ì¤‘ë‹¨
            if self.countdown_active:
                self.countdown_active = False
                st.session_state.capture_message = "â³ ì¡°ê±´ ë¯¸ë‹¬ë¡œ ì¹´ìš´íŠ¸ë‹¤ìš´ ì¤‘ë‹¨."

        # ---------------- 5. ìº¡ì²˜ ì´ë¯¸ì§€ ìœ ì§€ ë° ë¦¬ì…‹ ----------------
        if self.captured:
            if time.time() - self.last_capture_time > 3.0:
                self.captured = False
                st.session_state.capture_message = "â³ ë‹¤ì‹œ ì´¬ì˜ ì¤€ë¹„ ì™„ë£Œ."

        # ---------------- 6. ìƒíƒœ í‘œì‹œ ----------------
        status_text = (
            f"Face: {face_detected} | V: {victory_detected} | "
            f"Ratio A(E-M): {ratio_ok_A} | Ratio B(N-M): {ratio_ok_B}"
        )
        cv2.putText(img, status_text,
                    (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)

        return av.VideoFrame.from_ndarray(img, format="bgr24")


# ---------------- Streamlit ë©”ì¸ í•¨ìˆ˜ ----------------
def main():
    st.set_page_config(page_title="ë¹„ìœ¨ & V ì‚¬ì¸ ê²€ì¶œê¸°", layout="wide")

    st.title("ğŸ“¸ ë¹„ìœ¨ ìµœì í™” V-ì‚¬ì¸ ìë™ ìº¡ì²˜ ì›¹ ì•±")
    st.markdown("""
        ëª¨ë“  ì¡°ê±´ì´ ì¶©ì¡±ë˜ë©´ **3ì´ˆ ì¹´ìš´íŠ¸ë‹¤ìš´** í›„ ìë™ìœ¼ë¡œ ìº¡ì²˜ë©ë‹ˆë‹¤. 3ì´ˆ ë™ì•ˆ ìì„¸ë¥¼ ìœ ì§€í•˜ì„¸ìš”!
    """)
    st.markdown("---")

    # Session State ì´ˆê¸°í™”
    if 'capture_ready' not in st.session_state:
        st.session_state.capture_ready = False
        st.session_state.captured_image_bytes = None
        st.session_state.capture_message = "ì¹´ë©”ë¼ë¥¼ ì¼œê³  ìì„¸ë¥¼ ì¡ì•„ì£¼ì„¸ìš”."

    col1, col2 = st.columns([2, 1])

    with col1:
        st.subheader("ì‹¤ì‹œê°„ ì›¹ìº  ìŠ¤íŠ¸ë¦¼ (ë¹„ì „ ì²˜ë¦¬)")
        webrtc_ctx = webrtc_streamer(
            key="media-pipe-detector",
            video_processor_factory=VideoProcessor,
            rtc_configuration=RTCConfiguration(
                {"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]}
            ),
            media_stream_constraints={"video": True, "audio": False},
            async_processing=True,
        )
        st.info(f"í˜„ì¬ ìƒíƒœ: **{st.session_state.capture_message}**")

    with col2:
        st.subheader("âœ… ìº¡ì²˜ ê²°ê³¼ ë° ë‹¤ìš´ë¡œë“œ")

        st.markdown(
            f"""
            **âœ… ìº¡ì²˜ ì¡°ê±´ (ëª¨ë‘ ì¶©ì¡±í•´ì•¼ í•¨):**
            * ì–¼êµ´ ê°ì§€ (Face Detected)
            * V-ì‚¬ì¸ ê°ì§€ (Victory Gesture)
            * **ëˆˆ-ì… ë¹„ìœ¨:** ${TARGET_A_MIN}\% \sim {TARGET_A_MAX}\%$
            * **ì½”-ì… ë¹„ìœ¨:** ${TARGET_B_MIN}\% \sim {TARGET_B_MAX}\%$
            """
        )

        # â­â­ í•µì‹¬: webrtc_ctx.video_processor_result í™•ì¸ ë¡œì§ ì œê±° â­â­
        # (Legacy API í™˜ê²½ì—ì„œëŠ” ì´ ì†ì„±ì´ ì—†ìœ¼ë¯€ë¡œ)

        # ìº¡ì²˜ëœ ì´ë¯¸ì§€ê°€ ìˆì„ ë•Œë§Œ í‘œì‹œ ë° ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ í™œì„±í™”
        if st.session_state.capture_ready and 'captured_image_bytes' in st.session_state and st.session_state.captured_image_bytes is not None:
            st.image(st.session_state.captured_image_bytes, caption="ìµœê·¼ ìº¡ì²˜ ì´ë¯¸ì§€", use_column_width=True)

            # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
            st.download_button(
                label="ğŸ–¼ï¸ ìº¡ì²˜ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ",
                data=st.session_state.captured_image_bytes,
                file_name=f"capture_optimal_{int(time.time())}.png",
                mime="image/png"
            )
        elif st.session_state.capture_ready == False:
            st.warning("ì•„ì§ ìº¡ì²˜ëœ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. ì¡°ê±´ì„ ì¶©ì¡±ì‹œì¼œë³´ì„¸ìš”!")


if __name__ == "__main__":
    main()